{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Browse results of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient('mongodb://localhost')['ulmfit_experiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(db['completed'].find({'type': 'Poleval1'}))\n",
    "flattened = [dict(id=x['_id'], **x['results'], **x['params']) for x in results]\n",
    "df = pd.DataFrame(flattened).set_index('id')\n",
    "\n",
    "df = df.assign(last_phase_cycles = df.training_phases.apply(lambda x: x[-1]['cyc_len']))\n",
    "df.drop_mult.fillna(0.5, inplace=True)\n",
    "df.cv_fold_num.fillna(0, inplace=True)\n",
    "df.bidir.fillna(False, inplace=True)\n",
    "df.bs.fillna(40, inplace=True)\n",
    "df.max_len.fillna(70*20, inplace=True)\n",
    "df = df.assign(num_phases = df.phase_stats.apply(lambda x: len(x)))\n",
    "# df.rnn_output_layers.fillna((-1,), inplace=True)\n",
    "to_drop = ['time_submitted', 'time_completed', 'dataset_path', 'encoder_subdir', 'train_losses', 'phase_stats', 'training_phases']\n",
    "sdf = df.loc[:, ~df.columns.isin(to_drop)].copy()\n",
    "phases = lambda num: pd.DataFrame([x for phase in df.loc[num].phase_stats for x in phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf.assign(best_avg_precision = df.phase_stats.apply(lambda x: max([ep['avg_precision'] for stage in x for ep in stage])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation_class</th>\n",
       "      <th>aggregation_params</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>bidir</th>\n",
       "      <th>bs</th>\n",
       "      <th>calc_test_score</th>\n",
       "      <th>callbacks</th>\n",
       "      <th>cv_fold_num</th>\n",
       "      <th>drop_mult</th>\n",
       "      <th>max_len</th>\n",
       "      <th>metrics</th>\n",
       "      <th>rnn_output_layers</th>\n",
       "      <th>last_phase_cycles</th>\n",
       "      <th>num_phases</th>\n",
       "      <th>best_avg_precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.494885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}</td>\n",
       "      <td>0.929816</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.492539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 100}</td>\n",
       "      <td>0.926332</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [100], 'att_dropouts': 0.2, 'agg_dim': 50}</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1, -2]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.479235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.929318</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.475909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [100], 'att_dropouts': 0.2, 'agg_dim': 100}</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.467918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.462036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}</td>\n",
       "      <td>0.925336</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.457667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.5, 'agg_dim': 50}</td>\n",
       "      <td>0.923843</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.442314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.924340</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1, -2]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.441098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.920856</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.435857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.921354</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.427769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>SimpleAttention</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.920358</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.922847</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-2]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.416614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>BranchingAttentionAggregation</td>\n",
       "      <td>{'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}</td>\n",
       "      <td>0.924838</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.921354</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.403211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>SimpleAttention</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.917870</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.359473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SimpleAttention</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.916376</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>[average_precision_score]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>[accuracy, f1]</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.326263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 aggregation_class  \\\n",
       "id                                   \n",
       "137  BranchingAttentionAggregation   \n",
       "141  BranchingAttentionAggregation   \n",
       "138  BranchingAttentionAggregation   \n",
       "139  BranchingAttentionAggregation   \n",
       "136  BranchingAttentionAggregation   \n",
       "132  BranchingAttentionAggregation   \n",
       "140  BranchingAttentionAggregation   \n",
       "133  BranchingAttentionAggregation   \n",
       "131  BranchingAttentionAggregation   \n",
       "130  BranchingAttentionAggregation   \n",
       "135  BranchingAttentionAggregation   \n",
       "127  BranchingAttentionAggregation   \n",
       "129  BranchingAttentionAggregation   \n",
       "123                SimpleAttention   \n",
       "134  BranchingAttentionAggregation   \n",
       "128  BranchingAttentionAggregation   \n",
       "126                       Baseline   \n",
       "125                SimpleAttention   \n",
       "124                SimpleAttention   \n",
       "\n",
       "                                                 aggregation_params  \\\n",
       "id                                                                    \n",
       "137    {'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}   \n",
       "141    {'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}   \n",
       "138   {'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 100}   \n",
       "139   {'att_hid_layers': [100], 'att_dropouts': 0.2, 'agg_dim': 50}   \n",
       "136    {'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}   \n",
       "132    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "140  {'att_hid_layers': [100], 'att_dropouts': 0.2, 'agg_dim': 100}   \n",
       "133    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "131    {'att_hid_layers': [50], 'att_dropouts': 0.2, 'agg_dim': 50}   \n",
       "130    {'att_hid_layers': [50], 'att_dropouts': 0.5, 'agg_dim': 50}   \n",
       "135    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "127    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "129      {'att_hid_layers': [], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "123                                                              {}   \n",
       "134    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "128    {'att_hid_layers': [50], 'att_dropouts': 0.0, 'agg_dim': 50}   \n",
       "126                                                              {}   \n",
       "125                                                              {}   \n",
       "124                                                              {}   \n",
       "\n",
       "    best_val_acc  bidir  bs  calc_test_score                  callbacks  \\\n",
       "id                                                                        \n",
       "137     0.927825  False  80            False  [average_precision_score]   \n",
       "141     0.929816  False  16            False  [average_precision_score]   \n",
       "138     0.926332  False  80            False  [average_precision_score]   \n",
       "139     0.927825  False  80            False  [average_precision_score]   \n",
       "136     0.931309  False  80            False  [average_precision_score]   \n",
       "132     0.929318  False  80            False  [average_precision_score]   \n",
       "140     0.926829  False  80            False  [average_precision_score]   \n",
       "133     0.926829  False  80            False  [average_precision_score]   \n",
       "131     0.925336  False  80            False  [average_precision_score]   \n",
       "130     0.923843  False  80            False  [average_precision_score]   \n",
       "135     0.924340  False  80            False  [average_precision_score]   \n",
       "127     0.920856  False  80            False  [average_precision_score]   \n",
       "129     0.921354  False  80            False  [average_precision_score]   \n",
       "123     0.920358  False  80            False  [average_precision_score]   \n",
       "134     0.922847  False  80            False  [average_precision_score]   \n",
       "128     0.924838  False  80            False  [average_precision_score]   \n",
       "126     0.921354  False  80            False  [average_precision_score]   \n",
       "125     0.917870  False  80            False  [average_precision_score]   \n",
       "124     0.916376  False  80            False  [average_precision_score]   \n",
       "\n",
       "     cv_fold_num  drop_mult  max_len         metrics rnn_output_layers  \\\n",
       "id                                                                       \n",
       "137            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "141            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "138            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "139            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "136            0        0.5     1400  [accuracy, f1]          [-1, -2]   \n",
       "132            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "140            0        0.5     1400  [accuracy, f1]              [-1]   \n",
       "133            0        0.7     1400  [accuracy, f1]              [-1]   \n",
       "131            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "130            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "135            0        1.0     1400  [accuracy, f1]          [-1, -2]   \n",
       "127            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "129            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "123            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "134            0        1.0     1400  [accuracy, f1]              [-2]   \n",
       "128            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "126            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "125            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "124            0        1.0     1400  [accuracy, f1]              [-1]   \n",
       "\n",
       "     last_phase_cycles  num_phases best_avg_precision  \n",
       "id                                                     \n",
       "137                 10           4           0.494885  \n",
       "141                 10           4           0.492539  \n",
       "138                 10           4           0.491210  \n",
       "139                 10           4           0.486555  \n",
       "136                 10           4           0.479235  \n",
       "132                 10           4           0.475909  \n",
       "140                 10           4           0.467918  \n",
       "133                 10           4           0.462036  \n",
       "131                 10           4           0.457667  \n",
       "130                 10           4           0.442314  \n",
       "135                 10           4           0.441098  \n",
       "127                 10           4           0.435857  \n",
       "129                 10           4           0.427769  \n",
       "123                 10           4           0.417672  \n",
       "134                 10           4           0.416614  \n",
       "128                 15           1           0.407548  \n",
       "126                 10           4           0.403211  \n",
       "125                 15           1           0.359473  \n",
       "124                 10           4           0.326263  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.sort_values('best_avg_precision', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-dev",
   "language": "python",
   "name": "fastai-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
